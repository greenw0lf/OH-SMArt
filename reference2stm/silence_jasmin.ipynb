{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bd79e-dae2-423d-9013-2bb87473a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jasmin comp_p silence script\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Paths to the audio files directory and the partly silenced audio files output directory\n",
    "#\n",
    "# !!! MAKE SURE TO CHANGE THESE IF YOU INTEND TO RUN THE CODE !!!\n",
    "audio_path = '/home/jovyan/evaluation/jasmin_comp_p/group5/'\n",
    "out_path = '/home/jovyan/evaluation/jasmin_comp_p/5_sil/'\n",
    "\n",
    "# Open the STM file\n",
    "#\n",
    "# !!! MAKE SURE TO CHANGE THIS TO THE PATH OF THE STM FILE !!!\n",
    "with open('/home/jovyan/evaluation/jasmin_comp_p/group5.stm') as file:\n",
    "    # Read the utterances\n",
    "    lines = file.readlines()\n",
    "    # Keeps track of the audio file we are currently processing\n",
    "    audiofile = ''\n",
    "    # Variable that stores the actual audio array\n",
    "    audio = ''\n",
    "\n",
    "    # Iterate thru the lines\n",
    "    for line in lines:\n",
    "        # Lines that are comments start with ;;, so we ignore them\n",
    "        if line[0] == ';':\n",
    "            continue\n",
    "        # Split the line on whitespace (whitespace is used as a delimiter for the\n",
    "        # columns of the STM file)\n",
    "        segments = line.split(' ')\n",
    "        # If the current utterance's file ID has changed\n",
    "        if segments[0] != audiofile:\n",
    "            # If there is an audio file currently being processed (if it's\n",
    "            # not the start of the script)\n",
    "            if audiofile != '':\n",
    "                # Save the audio with silenced parts\n",
    "                audio.export(out_path + audiofile + '.wav', format='wav')\n",
    "            # Update the file name of the currently processed audio file\n",
    "            audiofile = segments[0]\n",
    "            # Load the audio to be partly silenced\n",
    "            audio = AudioSegment.from_file(audio_path + audiofile + '.wav')\n",
    "            # Get the 2 channels\n",
    "            channels = audio.split_to_mono()\n",
    "            # Process only the speaker channel (1st one)\n",
    "            audio = channels[0]\n",
    "        # This is a gap where the speaker does not talk\n",
    "        if segments[2] == 'inter_segment_gap':\n",
    "            start = float(segments[3]) * 1000\n",
    "            end = float(segments[4]) * 1000\n",
    "            # Create a silence as long as the inter_segment_gap\n",
    "            silence = AudioSegment.silent(duration=end-start)\n",
    "            # Modify the audio such that we add the silence above where inter_segment_gap was\n",
    "            audio = audio[:int(start)] + silence + audio[int(end):]\n",
    "\n",
    "    # Since we exit the loop before we are able to save the last audio file,\n",
    "    # we make sure we save it here\n",
    "    audio.export(out_path + audiofile + '.wav', format='wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest_venv",
   "language": "python",
   "name": "latest_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
