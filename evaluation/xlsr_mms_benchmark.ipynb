{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7adfd9-7558-4caa-b63e-6abd4411f72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### CODE CELL FOR RUNNING MMS (1B-ALL OR 1B-FL102)\n",
    "\n",
    "from transformers import pipeline, Wav2Vec2ForCTC, AutoProcessor\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# Options used: \"facebook/mms-1b-all\" (pretrained on 1162 languages)\n",
    "# or \"facebook/mms-1b-fl102\" (pretrained on 102 languages)\n",
    "model_id = \"facebook/mms-1b-all\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
    "\n",
    "# Loading the model\n",
    "processor.tokenizer.set_target_lang(\"nld\")\n",
    "model.load_adapter(\"nld\")\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=model, device=0, tokenizer=processor.tokenizer, feature_extractor=processor.feature_extractor,\n",
    "                        chunk_length_s=10, stride_length_s=(4, 2)) # as recommended here: https://huggingface.co/blog/asr-chunking\n",
    "\n",
    "# Keeping track of progress (how many files processed/total)\n",
    "i = 0\n",
    "recordings_path = '/evaluation/vl/jasmin/comp_p/5_sil/'\n",
    "out_path = '/evaluation/mms-1b-all/jasmin_vl/p5/'\n",
    "\n",
    "for recording in os.listdir(recordings_path):\n",
    "    words = transcriber(recordings_path + recording, return_timestamps=\"word\")\n",
    "    i += 1\n",
    "\n",
    "    # Converting to JSON format of Whisper\n",
    "    words_to_add = []\n",
    "    for word in words[\"chunks\"]:\n",
    "        words_to_add.append({\n",
    "            \"text\": word[\"text\"],\n",
    "            \"start\": word[\"timestamp\"][0],\n",
    "            \"end\": word[\"timestamp\"][1],\n",
    "            \"confidence\": 1  # since no confidence/prob is provided, a default of 1 is used\n",
    "        })\n",
    "\n",
    "    # Only a list of words is outputted by MMS which is why we add \"placeholder\" to text\n",
    "    # (and it is not relevant anyway as we will convert this output to CTM format\n",
    "    # which only looks at words and their timestamps)\n",
    "    result = {\"segments\": [{\n",
    "        \"text\": \"placeholder\",\n",
    "        \"words\": words_to_add\n",
    "    }]}\n",
    "\n",
    "    with open(out_path + recording[:-3] + 'json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, indent = 2, ensure_ascii = False)\n",
    "        print(str(i) + '/' + str(len(os.listdir(recordings_path))))\n",
    "        print(recording[:-4] + ' has been transcribed')\n",
    "        # Unfortunately, only the total time is logged into a file\n",
    "        print(f\"gpu used {torch.cuda.max_memory_allocated(device='cuda:0') / float(1e9)} GB memory\")\n",
    "        torch.cuda.reset_peak_memory_stats(device='cuda:0')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_s = end - start\n",
    "print('Time spent evaluating: ' + str(datetime.timedelta(seconds=time_s)))\n",
    "with open(out_path + 'a_time_spent.txt', 'w') as f:\n",
    "    f.write(str(datetime.timedelta(seconds=time_s)))\n",
    "\n",
    "# free GPU memory\n",
    "del transcriber\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cd1f0-9d79-49a6-9b7c-02f5a02b2954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### CODE CELL FOR RUNNING XLS-R\n",
    "# Only difference is in loading the model\n",
    "\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model='jonatasgrosman/wav2vec2-xls-r-1b-dutch', device=0,\n",
    "                        chunk_length_s=10, stride_length_s=(4, 2)) # as recommended here: https://huggingface.co/blog/asr-chunking\n",
    "print(f\"loading XLS-R mem usage: {torch.cuda.max_memory_allocated(device='cuda:0') / float(1e9)} GB memory\")\n",
    "torch.cuda.reset_peak_memory_stats(device='cuda:0')\n",
    "\n",
    "i = 0\n",
    "recordings_path = '/evaluation/vl/jasmin/comp_p/5_sil/'\n",
    "out_path = '/evaluation/xlsr/jasmin_vl/p5/'\n",
    "\n",
    "for recording in os.listdir(recordings_path):\n",
    "    words = transcriber(recordings_path + recording, return_timestamps=\"word\")\n",
    "    i += 1\n",
    "\n",
    "    words_to_add = []\n",
    "    for word in words[\"chunks\"]:\n",
    "        words_to_add.append({\n",
    "            \"text\": word[\"text\"],\n",
    "            \"start\": word[\"timestamp\"][0],\n",
    "            \"end\": word[\"timestamp\"][1],\n",
    "            \"confidence\": 1\n",
    "        })\n",
    "    result = {\"segments\":[{\n",
    "        \"text\": \"placeholder\",\n",
    "        \"words\": words_to_add\n",
    "    }]}\n",
    "\n",
    "    with open(out_path + recording[:-3] + 'json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, indent = 2, ensure_ascii = False)\n",
    "        print(str(i) + '/' + str(len(os.listdir(recordings_path))))\n",
    "        print(recording[:-4] + ' has been transcribed')\n",
    "        print(f\"gpu used {torch.cuda.max_memory_allocated(device='cuda:0') / float(1e9)} GB memory\")\n",
    "        torch.cuda.reset_peak_memory_stats(device='cuda:0')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_s = end - start\n",
    "print('Time spent evaluating: ' + str(datetime.timedelta(seconds=time_s)))\n",
    "with open(out_path + 'a_time_spent.txt', 'w') as f:\n",
    "    f.write(str(datetime.timedelta(seconds=time_s)))\n",
    "\n",
    "# free GPU memory\n",
    "del transcriber\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest_venv",
   "language": "python",
   "name": "latest_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
