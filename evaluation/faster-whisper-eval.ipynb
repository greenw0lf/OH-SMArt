{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SURE TO INSTALL THE DEPENDENCIES BELOW (RECOMMENDED TO DO IN A VIRTUAL ENV)\n",
    "from faster_whisper import WhisperModel\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "\n",
    "# Starting the log of time it takes to evaluate\n",
    "start = time.time()\n",
    "# Loading the faster-whisper model\n",
    "#\n",
    "# To use the CPU instead of the GPU:\n",
    "# - change \"cuda\" to \"cpu\"\n",
    "# - remove `device_index=0`\n",
    "# - change `compute_type` from \"float16\" to \"float32\" or \"int8\"\n",
    "#\n",
    "# You can also use fine-tuned models, but for that check the doc of \"faster-whisper\"\n",
    "model = WhisperModel('large-v2', device=\"cuda\", device_index=0, compute_type=\"float16\")\n",
    "\n",
    "# !!! Change the path to the dir where the audio files are stored !!!\n",
    "for file in os.listdir('/home/jovyan/evaluation/jasmin_comp_p/5_sil/'):\n",
    "    # the beam_size, best_of, and temperature settings correspond to the ones used by the original\n",
    "    # implementation of Whisper by OpenAI\n",
    "    #\n",
    "    # !!! Also change the path here !!!\n",
    "    segments, info = model.transcribe('/home/jovyan/evaluation/jasmin_comp_p/5_sil/' + file, vad_filter=True, beam_size=5,\\\n",
    "                                      best_of=5, temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0), language=\"nl\", word_timestamps=True)\n",
    "    segments_to_add = []\n",
    "    # Reformatting the output to match the one seen in \"whisper-timestamped\" implementation\n",
    "    for segment in segments:\n",
    "        words_to_add = []\n",
    "        for word in segment.words:\n",
    "            words_to_add.append({\n",
    "                # There was an issue with spaces being inserted at the beginning of words\n",
    "                # To mitigate, I used `.lstrip()`\n",
    "                \"text\": word.word.lstrip(),\n",
    "                \"start\": word.start,\n",
    "                \"end\": word.end,\n",
    "                \"confidence\": word.probability\n",
    "            })\n",
    "        segments_to_add.append({\n",
    "            \"id\": segment.id,\n",
    "            \"seek\": segment.seek,\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text,\n",
    "            \"tokens\": segment.tokens,\n",
    "            \"temperature\": segment.temperature,\n",
    "            \"avg_logprob\": segment.avg_logprob,\n",
    "            \"compression_ratio\": segment.compression_ratio,\n",
    "            \"no_speech_prob\": segment.no_speech_prob,\n",
    "            \"words\": words_to_add\n",
    "        })\n",
    "    result = {\"segments\": segments_to_add}\n",
    "    # Dump the results in a JSON file for postprocessing\n",
    "    #\n",
    "    # !!! Change the path to wherever you want to store the results !!!\n",
    "    with open('/home/jovyan/evaluation/faster-whisper/group5_p/vad2/' + file[:-3] + 'json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, indent = 2, ensure_ascii = False)\n",
    "        print(file[:-4] + ' has been transcribed')\n",
    "        print(f\"gpu used {torch.cuda.max_memory_allocated(device='cuda:0') / float(1e9)} GB memory\")\n",
    "        torch.cuda.reset_peak_memory_stats(device='cuda:0')\n",
    "\n",
    "# End logging as evaluation finished\n",
    "end = time.time()\n",
    "time_s = end - start\n",
    "# Print out the time, as well as save in a txt file in case the cell output bugs out\n",
    "# (that happened to me so better be safe than sorry)\n",
    "print('Time spent evaluating: ' + str(datetime.timedelta(seconds=time_s)))\n",
    "\n",
    "# !!! Change the path to wherever you want to store the results !!!\n",
    "with open('/home/jovyan/evaluation/faster-whisper/group5_p/vad2/a_time_spent.txt', 'w') as f:\n",
    "    f.write(str(datetime.timedelta(seconds=time_s)))\n",
    "\n",
    "# Freeing up memory (restarting the kernel is more effective and consistent)\n",
    "del model\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
